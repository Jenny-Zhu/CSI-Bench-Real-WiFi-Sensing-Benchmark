{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ad34ec3-3594-421c-bdde-33f0c1572832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd3802b2-7db6-4396-8891-9acfc6365c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/MotionSourceRecognition/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/mlp: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 617.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\mlp\\params_d0537c49, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/lstm: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 853.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\lstm\\params_c579fb8f, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/resnet18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 878.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\resnet18\\params_1f994ff2, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/transformer: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1099.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\transformer\\params_a222f2d6, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/vit: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 987.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\vit\\params_11a038cd, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/patchtst: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1003.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\patchtst\\params_643be153, skipping\n",
      "Found 4 experiments for supervised/MotionSourceRecognition/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/MotionSourceRecognition/timesformer1d: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 941.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\MotionSourceRecognition\\timesformer1d\\params_0dac0144, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/mlp: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 974.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\mlp\\params_e82c47fd, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/lstm: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1552.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\lstm\\params_103a2ab2, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/resnet18: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1567.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\resnet18\\params_f3993c61, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/transformer: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1266.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\transformer\\params_da0536fb, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/vit: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1068.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\vit\\params_7d6cf50b, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/patchtst: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 864.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\patchtst\\params_2ac42674, skipping\n",
      "Found 2 experiments for supervised/BreathingDetection_Subset/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/BreathingDetection_Subset/timesformer1d: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1247.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\BreathingDetection_Subset\\timesformer1d\\params_eaf7d314, skipping\n",
      "Found 7 experiments for supervised/Localization/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/mlp: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 994.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\mlp\\params_5f8b7681, skipping\n",
      "Seed not available in C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\mlp\\params_c21f4b60, skipping\n",
      "Found 7 experiments for supervised/Localization/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/lstm: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1390.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\lstm\\params_1b0e1c8b, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\lstm\\params_58042d4f, skipping\n",
      "Found 7 experiments for supervised/Localization/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/resnet18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1175.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\resnet18\\params_0637f687, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\resnet18\\params_134c9969, skipping\n",
      "Found 7 experiments for supervised/Localization/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/transformer: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1175.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\transformer\\params_42f9b535, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\transformer\\params_9761304b, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\transformer\\params_d4cd0e38, skipping\n",
      "Found 7 experiments for supervised/Localization/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/vit: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1215.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\vit\\params_04696cd8, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\vit\\params_c90efad6, skipping\n",
      "Found 7 experiments for supervised/Localization/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/patchtst: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1189.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\patchtst\\params_451e1069, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\patchtst\\params_c52077c2, skipping\n",
      "Found 7 experiments for supervised/Localization/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/Localization/timesformer1d: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 905.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\timesformer1d\\params_8fae46c8, skipping\n",
      "Missing files for C:\\Users\\weiha\\Desktop\\benchmark_result\\supervised\\Localization\\timesformer1d\\params_ad406c14, skipping\n",
      "Found 4 experiments for supervised/FallDetection/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/mlp: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1247.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/lstm: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 742.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/resnet18: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1282.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/transformer: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1762.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/vit: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2593.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/patchtst: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2564.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 experiments for supervised/FallDetection/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/FallDetection/timesformer1d: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1145.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/mlp: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/lstm: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/resnet18: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/transformer: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/vit: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/patchtst: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/ProximityRecognition/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/ProximityRecognition/timesformer1d: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/mlp: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/lstm: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/resnet18: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/transformer: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/vit: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/patchtst: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanActivityRecognition/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanActivityRecognition/timesformer1d: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/mlp: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/lstm: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/resnet18: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/transformer: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/vit: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/patchtst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/patchtst: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 experiments for supervised/HumanIdentification/timesformer1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing supervised/HumanIdentification/timesformer1d: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MotionSourceRecognition - mlp (count: 3)\n",
      "  test_hard_loss: 0.0534\n",
      "  test_hard_accuracy: 0.9791\n",
      "  test_medium_loss: 0.0281\n",
      "  test_medium_accuracy: 0.9917\n",
      "  test_loss: 0.0330\n",
      "  test_accuracy: 0.9886\n",
      "  test_easy_loss: 0.0278\n",
      "  test_easy_accuracy: 0.9862\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - lstm (count: 3)\n",
      "  test_hard_loss: 0.0966\n",
      "  test_hard_accuracy: 0.9767\n",
      "  test_medium_loss: 0.0538\n",
      "  test_medium_accuracy: 0.9866\n",
      "  test_loss: 0.0631\n",
      "  test_accuracy: 0.9842\n",
      "  test_easy_loss: 0.0633\n",
      "  test_easy_accuracy: 0.9826\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - resnet18 (count: 3)\n",
      "  test_hard_loss: 0.0185\n",
      "  test_hard_accuracy: 0.9948\n",
      "  test_medium_loss: 0.0127\n",
      "  test_medium_accuracy: 0.9957\n",
      "  test_loss: 0.0145\n",
      "  test_accuracy: 0.9956\n",
      "  test_easy_loss: 0.0184\n",
      "  test_easy_accuracy: 0.9964\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - transformer (count: 3)\n",
      "  test_hard_loss: 0.0529\n",
      "  test_hard_accuracy: 0.9824\n",
      "  test_medium_loss: 0.0456\n",
      "  test_medium_accuracy: 0.9867\n",
      "  test_loss: 0.0455\n",
      "  test_accuracy: 0.9861\n",
      "  test_easy_loss: 0.0326\n",
      "  test_easy_accuracy: 0.9884\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - vit (count: 3)\n",
      "  test_hard_loss: 0.0473\n",
      "  test_hard_accuracy: 0.9859\n",
      "  test_medium_loss: 0.0301\n",
      "  test_medium_accuracy: 0.9909\n",
      "  test_loss: 0.0336\n",
      "  test_accuracy: 0.9898\n",
      "  test_easy_loss: 0.0316\n",
      "  test_easy_accuracy: 0.9893\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - patchtst (count: 3)\n",
      "  test_hard_loss: 0.0314\n",
      "  test_hard_accuracy: 0.9894\n",
      "  test_medium_loss: 0.0367\n",
      "  test_medium_accuracy: 0.9893\n",
      "  test_loss: 0.0385\n",
      "  test_accuracy: 0.9886\n",
      "  test_easy_loss: 0.0607\n",
      "  test_easy_accuracy: 0.9835\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "MotionSourceRecognition - timesformer1d (count: 3)\n",
      "  test_hard_loss: 0.0590\n",
      "  test_hard_accuracy: 0.9807\n",
      "  test_medium_loss: 0.0575\n",
      "  test_medium_accuracy: 0.9848\n",
      "  test_loss: 0.0578\n",
      "  test_accuracy: 0.9838\n",
      "  test_easy_loss: 0.0579\n",
      "  test_easy_accuracy: 0.9830\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "BreathingDetection_Subset - mlp (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0827\n",
      "  test_accuracy: 0.9759\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0825\n",
      "  test_medium_id_accuracy: 0.9754\n",
      "  test_easy_id_loss: 0.0505\n",
      "  test_easy_id_accuracy: 0.9857\n",
      "  test_hard_id_loss: 0.1185\n",
      "  test_hard_id_accuracy: 0.9654\n",
      "\n",
      "BreathingDetection_Subset - lstm (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0558\n",
      "  test_accuracy: 0.9881\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0522\n",
      "  test_medium_id_accuracy: 0.9874\n",
      "  test_easy_id_loss: 0.0368\n",
      "  test_easy_id_accuracy: 0.9931\n",
      "  test_hard_id_loss: 0.0798\n",
      "  test_hard_id_accuracy: 0.9830\n",
      "\n",
      "BreathingDetection_Subset - resnet18 (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0449\n",
      "  test_accuracy: 0.9836\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0461\n",
      "  test_medium_id_accuracy: 0.9820\n",
      "  test_easy_id_loss: 0.0374\n",
      "  test_easy_id_accuracy: 0.9869\n",
      "  test_hard_id_loss: 0.0522\n",
      "  test_hard_id_accuracy: 0.9812\n",
      "\n",
      "BreathingDetection_Subset - transformer (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0893\n",
      "  test_accuracy: 0.9754\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.1047\n",
      "  test_medium_id_accuracy: 0.9697\n",
      "  test_easy_id_loss: 0.0739\n",
      "  test_easy_id_accuracy: 0.9808\n",
      "  test_hard_id_loss: 0.0935\n",
      "  test_hard_id_accuracy: 0.9742\n",
      "\n",
      "BreathingDetection_Subset - vit (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0275\n",
      "  test_accuracy: 0.9932\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0267\n",
      "  test_medium_id_accuracy: 0.9931\n",
      "  test_easy_id_loss: 0.0201\n",
      "  test_easy_id_accuracy: 0.9954\n",
      "  test_hard_id_loss: 0.0362\n",
      "  test_hard_id_accuracy: 0.9908\n",
      "\n",
      "BreathingDetection_Subset - patchtst (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0496\n",
      "  test_accuracy: 0.9877\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0488\n",
      "  test_medium_id_accuracy: 0.9863\n",
      "  test_easy_id_loss: 0.0370\n",
      "  test_easy_id_accuracy: 0.9912\n",
      "  test_hard_id_loss: 0.0643\n",
      "  test_hard_id_accuracy: 0.9852\n",
      "\n",
      "BreathingDetection_Subset - timesformer1d (count: 1)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0784\n",
      "  test_accuracy: 0.9869\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0869\n",
      "  test_medium_id_accuracy: 0.9832\n",
      "  test_easy_id_loss: 0.0659\n",
      "  test_easy_id_accuracy: 0.9889\n",
      "  test_hard_id_loss: 0.0852\n",
      "  test_hard_id_accuracy: 0.9877\n",
      "\n",
      "Localization - mlp (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.4515\n",
      "  test_accuracy: 0.8663\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.1470\n",
      "  test_medium_id_accuracy: 0.9510\n",
      "  test_easy_id_loss: 0.3352\n",
      "  test_easy_id_accuracy: 0.9124\n",
      "  test_hard_id_loss: 0.6698\n",
      "  test_hard_id_accuracy: 0.7967\n",
      "\n",
      "Localization - lstm (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0412\n",
      "  test_accuracy: 0.9893\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0026\n",
      "  test_medium_id_accuracy: 0.9992\n",
      "  test_easy_id_loss: 0.0195\n",
      "  test_easy_id_accuracy: 0.9955\n",
      "  test_hard_id_loss: 0.0734\n",
      "  test_hard_id_accuracy: 0.9807\n",
      "\n",
      "Localization - resnet18 (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0002\n",
      "  test_accuracy: 1.0000\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0002\n",
      "  test_medium_id_accuracy: 1.0000\n",
      "  test_easy_id_loss: 0.0002\n",
      "  test_easy_id_accuracy: 1.0000\n",
      "  test_hard_id_loss: 0.0002\n",
      "  test_hard_id_accuracy: 1.0000\n",
      "\n",
      "Localization - transformer (count: 4)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0372\n",
      "  test_accuracy: 0.9927\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0021\n",
      "  test_medium_id_accuracy: 0.9990\n",
      "  test_easy_id_loss: 0.0322\n",
      "  test_easy_id_accuracy: 0.9930\n",
      "  test_hard_id_loss: 0.0569\n",
      "  test_hard_id_accuracy: 0.9895\n",
      "\n",
      "Localization - vit (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0121\n",
      "  test_accuracy: 0.9972\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0051\n",
      "  test_medium_id_accuracy: 0.9992\n",
      "  test_easy_id_loss: 0.0089\n",
      "  test_easy_id_accuracy: 0.9978\n",
      "  test_hard_id_loss: 0.0174\n",
      "  test_hard_id_accuracy: 0.9960\n",
      "\n",
      "Localization - patchtst (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0050\n",
      "  test_accuracy: 0.9990\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0016\n",
      "  test_medium_id_accuracy: 0.9992\n",
      "  test_easy_id_loss: 0.0039\n",
      "  test_easy_id_accuracy: 0.9994\n",
      "  test_hard_id_loss: 0.0073\n",
      "  test_hard_id_accuracy: 0.9985\n",
      "\n",
      "Localization - timesformer1d (count: 5)\n",
      "  test_hard_loss: nan\n",
      "  test_hard_accuracy: nan\n",
      "  test_medium_loss: nan\n",
      "  test_medium_accuracy: nan\n",
      "  test_loss: 0.0065\n",
      "  test_accuracy: 0.9984\n",
      "  test_easy_loss: nan\n",
      "  test_easy_accuracy: nan\n",
      "  test_medium_id_loss: 0.0026\n",
      "  test_medium_id_accuracy: 0.9992\n",
      "  test_easy_id_loss: 0.0117\n",
      "  test_easy_id_accuracy: 0.9972\n",
      "  test_hard_id_loss: 0.0050\n",
      "  test_hard_id_accuracy: 0.9989\n",
      "\n",
      "FallDetection - mlp (count: 4)\n",
      "  test_hard_loss: 0.6260\n",
      "  test_hard_accuracy: 0.6370\n",
      "  test_medium_loss: 0.5833\n",
      "  test_medium_accuracy: 0.7059\n",
      "  test_loss: 0.1765\n",
      "  test_accuracy: 0.9216\n",
      "  test_easy_loss: 0.1331\n",
      "  test_easy_accuracy: 0.9484\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - lstm (count: 4)\n",
      "  test_hard_loss: 0.6028\n",
      "  test_hard_accuracy: 0.6712\n",
      "  test_medium_loss: 0.8682\n",
      "  test_medium_accuracy: 0.6912\n",
      "  test_loss: 0.1313\n",
      "  test_accuracy: 0.9493\n",
      "  test_easy_loss: 0.0800\n",
      "  test_easy_accuracy: 0.9762\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - resnet18 (count: 4)\n",
      "  test_hard_loss: 0.6790\n",
      "  test_hard_accuracy: 0.6884\n",
      "  test_medium_loss: 0.6527\n",
      "  test_medium_accuracy: 0.7794\n",
      "  test_loss: 0.1380\n",
      "  test_accuracy: 0.9488\n",
      "  test_easy_loss: 0.0852\n",
      "  test_easy_accuracy: 0.9727\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - transformer (count: 4)\n",
      "  test_hard_loss: 0.5969\n",
      "  test_hard_accuracy: 0.6507\n",
      "  test_medium_loss: 0.7831\n",
      "  test_medium_accuracy: 0.6912\n",
      "  test_loss: 0.1428\n",
      "  test_accuracy: 0.9428\n",
      "  test_easy_loss: 0.0946\n",
      "  test_easy_accuracy: 0.9708\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - vit (count: 4)\n",
      "  test_hard_loss: 0.5941\n",
      "  test_hard_accuracy: 0.6575\n",
      "  test_medium_loss: 0.6074\n",
      "  test_medium_accuracy: 0.7794\n",
      "  test_loss: 0.1352\n",
      "  test_accuracy: 0.9478\n",
      "  test_easy_loss: 0.0898\n",
      "  test_easy_accuracy: 0.9740\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - patchtst (count: 4)\n",
      "  test_hard_loss: 0.6131\n",
      "  test_hard_accuracy: 0.6267\n",
      "  test_medium_loss: 0.8330\n",
      "  test_medium_accuracy: 0.6176\n",
      "  test_loss: 0.1330\n",
      "  test_accuracy: 0.9403\n",
      "  test_easy_loss: 0.0816\n",
      "  test_easy_accuracy: 0.9713\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n",
      "\n",
      "FallDetection - timesformer1d (count: 4)\n",
      "  test_hard_loss: 0.6263\n",
      "  test_hard_accuracy: 0.6575\n",
      "  test_medium_loss: 0.5601\n",
      "  test_medium_accuracy: 0.6765\n",
      "  test_loss: 0.1491\n",
      "  test_accuracy: 0.9386\n",
      "  test_easy_loss: 0.1033\n",
      "  test_easy_accuracy: 0.9658\n",
      "  test_medium_id_loss: nan\n",
      "  test_medium_id_accuracy: nan\n",
      "  test_easy_id_loss: nan\n",
      "  test_easy_id_accuracy: nan\n",
      "  test_hard_id_loss: nan\n",
      "  test_hard_id_accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "# Configuration - You can modify these variables\n",
    "data_dir = r\"C:\\Users\\weiha\\Desktop\\benchmark_result\"  # Base directory containing results\n",
    "pipeline_list = [\"supervised\"]  # List of pipelines to analyze\n",
    "task_name_list =[\"MotionSourceRecognition\",\"BreathingDetection_Subset\",\"Localization\",\"FallDetection\",\"ProximityRecognition\",\"HumanActivityRecognition\",\"HumanIdentification\"]\n",
    "# task_name_list = [\"BreathingDetection_Subset\"]  # List of tasks to analyze\n",
    "model_name_list = [\"mlp\", \"lstm\", \"resnet18\", \"transformer\", \"vit\", \"patchtst\", \"timesformer1d\"] # List of models to analyze\n",
    "\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_data = []\n",
    "\n",
    "# Iterate through all combinations\n",
    "for pipeline in pipeline_list:\n",
    "    for task_name in task_name_list:\n",
    "        for model_name in model_name_list:\n",
    "            # Find all experiment folders for the current combination\n",
    "            exp_pattern = os.path.join(data_dir, pipeline, task_name, model_name, \"params_*\")\n",
    "            exp_folders = glob(exp_pattern)\n",
    "            \n",
    "            print(f\"Found {len(exp_folders)} experiments for {pipeline}/{task_name}/{model_name}\")\n",
    "            \n",
    "            # Process each experiment\n",
    "            for exp_folder in tqdm(exp_folders, desc=f\"Processing {pipeline}/{task_name}/{model_name}\"):\n",
    "                # Extract experiment ID\n",
    "                exp_id = os.path.basename(exp_folder)\n",
    "                \n",
    "                # Define paths for config and results files\n",
    "                config_filename = f\"{model_name}_{task_name}_config.json\"\n",
    "                results_filename = f\"{model_name}_{task_name}_results.json\"\n",
    "                \n",
    "                config_path = os.path.join(exp_folder, config_filename)\n",
    "                results_path = os.path.join(exp_folder, results_filename)\n",
    "                \n",
    "                # Skip if either file doesn't exist\n",
    "                if not os.path.exists(config_path) or not os.path.exists(results_path):\n",
    "                    print(f\"Missing files for {exp_folder}, skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Read config file\n",
    "                try:\n",
    "                    with open(config_path, 'r') as f:\n",
    "                        config_data = json.load(f)\n",
    "                    \n",
    "                    # Extract required fields from config\n",
    "                    learning_rate = config_data.get('learning_rate')\n",
    "                    weight_decay = config_data.get('weight_decay')\n",
    "                    seed = config_data.get('seed')\n",
    "                    batch_size = config_data.get('batch_size')\n",
    "                    \n",
    "                    # Skip if seed is not available (old version)\n",
    "                    if seed is None:\n",
    "                        print(f\"Seed not available in {exp_folder}, skipping\")\n",
    "                        continue\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading config file {config_path}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Read results file\n",
    "                try:\n",
    "                    with open(results_path, 'r') as f:\n",
    "                        results_data_json = json.load(f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading results file {results_path}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Create a dictionary for the current experiment\n",
    "                exp_result = {\n",
    "                    'pipeline': pipeline,\n",
    "                    'task_name': task_name,\n",
    "                    'model_name': model_name,\n",
    "                    'experiment_id': exp_id,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'weight_decay': weight_decay,\n",
    "                    'batch_size':batch_size,\n",
    "                    'seed': seed,\n",
    "                }\n",
    "                \n",
    "                # Extract test results for all test sets\n",
    "                for test_name, test_results in results_data_json.items():\n",
    "                    if isinstance(test_results, dict):\n",
    "                        for metric_name, metric_value in test_results.items():\n",
    "                            column_name = f\"{test_name}_{metric_name}\"\n",
    "                            exp_result[column_name] = metric_value\n",
    "                \n",
    "                # Add to results list\n",
    "                results_data.append(exp_result)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "\n",
    "for task in task_name_list:\n",
    "    for model in model_name_list:\n",
    "        task_model_df = results_df[(results_df['task_name'] == task) & (results_df['model_name'] == model)]\n",
    "        if not task_model_df.empty:\n",
    "            print(f\"\\n{task} - {model} (count: {len(task_model_df)})\")\n",
    "            \n",
    "            # Find metrics columns\n",
    "            metric_columns = [col for col in task_model_df.columns if any(col.endswith(m) for m in ['_loss', '_accuracy', '_f1'])]\n",
    "            \n",
    "            if metric_columns:\n",
    "                avg_metrics = task_model_df[metric_columns].mean()\n",
    "                for metric, value in avg_metrics.items():\n",
    "                    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "results_df = results_df[results_df[\"batch_size\"] == 128].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f6a828b-7930-48de-b126-795cadb97fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.987999</td>\n",
       "      <td>0.987996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.988466</td>\n",
       "      <td>0.988469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.989401</td>\n",
       "      <td>0.989401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.985973</td>\n",
       "      <td>0.985980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.984414</td>\n",
       "      <td>0.984434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>patchtst</td>\n",
       "      <td>0.949254</td>\n",
       "      <td>0.949204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.944279</td>\n",
       "      <td>0.944166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.936318</td>\n",
       "      <td>0.936412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.923943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.950190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task_name     model_name  test_accuracy  test_f1_score\n",
       "0   MotionSourceRecognition            mlp       0.987999       0.987996\n",
       "1   MotionSourceRecognition            mlp       0.988466       0.988469\n",
       "2   MotionSourceRecognition            mlp       0.989401       0.989401\n",
       "3   MotionSourceRecognition           lstm       0.985973       0.985980\n",
       "4   MotionSourceRecognition           lstm       0.984414       0.984434\n",
       "..                      ...            ...            ...            ...\n",
       "79            FallDetection       patchtst       0.949254       0.949204\n",
       "80            FallDetection  timesformer1d       0.944279       0.944166\n",
       "81            FallDetection  timesformer1d       0.936318       0.936412\n",
       "82            FallDetection  timesformer1d       0.923383       0.923943\n",
       "83            FallDetection  timesformer1d       0.950249       0.950190\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[\"task_name\",\"model_name\",\"test_accuracy\", \"test_f1_score\"]]\n",
    "# results_df[results_df['task_name'] == 'BreathingDetection_Subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cea80651-cd86-410c-a99b-7732228fab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to all_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "output_path = \"all_results_summary.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nResults saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a037cc-c417-4e30-8dba-60650d7fc22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1506f02-e210-4254-9cee-4ae2b148a6ed",
   "metadata": {},
   "source": [
    "## Generate Error Bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7b63085-3c72-40ce-b961-e123e175afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_errorbar_summary_with_latex(df: pd.DataFrame,\n",
    "                                        task_list,\n",
    "                                        metric_columns,\n",
    "                                        learning_rate=0.001,\n",
    "                                        weight_decay=0.00001,\n",
    "                                        model_order=None,\n",
    "                                        precision=4):\n",
    "\n",
    "    # Filter by learning rate and weight decay\n",
    "    filtered_df = df[(df[\"learning_rate\"] == learning_rate) & \n",
    "                     (df[\"weight_decay\"] == weight_decay)]\n",
    "\n",
    "    # Calculate mean ± std per model per task\n",
    "    summary = []\n",
    "    for task in task_list:\n",
    "        task_df = filtered_df[filtered_df[\"task_name\"] == task]\n",
    "        for model in sorted(task_df[\"model_name\"].unique()):\n",
    "            row = {\"task\": task, \"model\": model}\n",
    "            model_df = task_df[task_df[\"model_name\"] == model]\n",
    "            for col in metric_columns:\n",
    "                if col in model_df.columns:\n",
    "                    values = model_df[col].dropna()\n",
    "                    if len(values) > 0:\n",
    "                        mean = values.mean()\n",
    "                        std = values.std(ddof=1)\n",
    "                        row[col] = f\"{mean:.{precision}f}±{std:.{precision}f}\"\n",
    "                    else:\n",
    "                        row[col] = \"--\"\n",
    "                else:\n",
    "                    row[col] = \"--\"\n",
    "            summary.append(row)\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "\n",
    "    # Prepare LaTeX data\n",
    "    latex_data = defaultdict(lambda: defaultdict(lambda: {\"accuracy\": \"--\", \"f1_score\": \"--\"}))\n",
    "    for _, row in summary_df.iterrows():\n",
    "        model = row[\"model\"]\n",
    "        task = row[\"task\"]\n",
    "        latex_data[model][task][\"accuracy\"] = row.get(metric_columns[0], \"--\")\n",
    "        latex_data[model][task][\"f1_score\"] = row.get(metric_columns[1], \"--\")\n",
    "\n",
    "    if model_order is None:\n",
    "        model_order = sorted(summary_df[\"model\"].unique())\n",
    "\n",
    "    # Generate LaTeX rows\n",
    "    latex_rows = []\n",
    "    for model in model_order:\n",
    "        acc_f1_values = []\n",
    "        for task in task_list:\n",
    "            acc = latex_data[model][task][\"accuracy\"]\n",
    "            f1 = latex_data[model][task][\"f1_score\"]\n",
    "            acc_f1_values.extend([acc, f1])\n",
    "        row_line = f\"{model.upper()} & \" + \" & \".join(acc_f1_values) + r\" \\\\\"\n",
    "        latex_rows.append(row_line)\n",
    "\n",
    "    # LaTeX header and footer\n",
    "    latex_table_header = r\"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Standard supervised evaluation on four core tasks. We report Accuracy and F1-score for each model.}\n",
    "\\label{tab:supervised-results}\n",
    "\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}{\n",
    "    >{\\centering\\arraybackslash}p{2.5cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
    "    >{\\centering\\arraybackslash}p{1.8cm}\n",
    "}\n",
    "     \\toprule\n",
    "    Model & \\multicolumn{2}{c|}{\\textbf{Motion Source Recognition}} & \\multicolumn{2}{c|}{\\textbf{Fall Detection}} & \\multicolumn{2}{c|}{\\textbf{Breathing Detection}} & \\multicolumn{2}{c}{\\textbf{Localization}} \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "    latex_table_footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}%\n",
    "}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    full_latex_code = latex_table_header + \"\\n\" + \"\\n\".join(latex_rows) + latex_table_footer\n",
    "    return summary_df, full_latex_code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc442928-2013-4a78-941f-76c0f996e3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.9842±0.0019</td>\n",
       "      <td>0.9842±0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.9886±0.0007</td>\n",
       "      <td>0.9886±0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>patchtst</td>\n",
       "      <td>0.9886±0.0019</td>\n",
       "      <td>0.9886±0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>0.9956±0.0007</td>\n",
       "      <td>0.9956±0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.9838±0.0017</td>\n",
       "      <td>0.9839±0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.9861±0.0027</td>\n",
       "      <td>0.9861±0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MotionSourceRecognition</td>\n",
       "      <td>vit</td>\n",
       "      <td>0.9898±0.0015</td>\n",
       "      <td>0.9898±0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.9493±0.0051</td>\n",
       "      <td>0.9492±0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.9216±0.0091</td>\n",
       "      <td>0.9217±0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>patchtst</td>\n",
       "      <td>0.9403±0.0074</td>\n",
       "      <td>0.9403±0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>0.9488±0.0026</td>\n",
       "      <td>0.9489±0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>0.9386±0.0116</td>\n",
       "      <td>0.9387±0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.9428±0.0072</td>\n",
       "      <td>0.9426±0.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FallDetection</td>\n",
       "      <td>vit</td>\n",
       "      <td>0.9478±0.0058</td>\n",
       "      <td>0.9477±0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Localization</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.9912±0.0027</td>\n",
       "      <td>0.9912±0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Localization</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.8714±0.0080</td>\n",
       "      <td>0.8690±0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Localization</td>\n",
       "      <td>patchtst</td>\n",
       "      <td>0.9991±0.0010</td>\n",
       "      <td>0.9991±0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Localization</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>1.0000±0.0000</td>\n",
       "      <td>1.0000±0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Localization</td>\n",
       "      <td>timesformer1d</td>\n",
       "      <td>1.0000±0.0000</td>\n",
       "      <td>1.0000±0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Localization</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.9927±0.0022</td>\n",
       "      <td>0.9927±0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Localization</td>\n",
       "      <td>vit</td>\n",
       "      <td>0.9968±0.0019</td>\n",
       "      <td>0.9968±0.0019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       task          model  test_accuracy  test_f1_score\n",
       "0   MotionSourceRecognition           lstm  0.9842±0.0019  0.9842±0.0019\n",
       "1   MotionSourceRecognition            mlp  0.9886±0.0007  0.9886±0.0007\n",
       "2   MotionSourceRecognition       patchtst  0.9886±0.0019  0.9886±0.0019\n",
       "3   MotionSourceRecognition       resnet18  0.9956±0.0007  0.9956±0.0007\n",
       "4   MotionSourceRecognition  timesformer1d  0.9838±0.0017  0.9839±0.0017\n",
       "5   MotionSourceRecognition    transformer  0.9861±0.0027  0.9861±0.0027\n",
       "6   MotionSourceRecognition            vit  0.9898±0.0015  0.9898±0.0015\n",
       "7             FallDetection           lstm  0.9493±0.0051  0.9492±0.0050\n",
       "8             FallDetection            mlp  0.9216±0.0091  0.9217±0.0092\n",
       "9             FallDetection       patchtst  0.9403±0.0074  0.9403±0.0073\n",
       "10            FallDetection       resnet18  0.9488±0.0026  0.9489±0.0026\n",
       "11            FallDetection  timesformer1d  0.9386±0.0116  0.9387±0.0113\n",
       "12            FallDetection    transformer  0.9428±0.0072  0.9426±0.0072\n",
       "13            FallDetection            vit  0.9478±0.0058  0.9477±0.0058\n",
       "14             Localization           lstm  0.9912±0.0027  0.9912±0.0026\n",
       "15             Localization            mlp  0.8714±0.0080  0.8690±0.0083\n",
       "16             Localization       patchtst  0.9991±0.0010  0.9991±0.0010\n",
       "17             Localization       resnet18  1.0000±0.0000  1.0000±0.0000\n",
       "18             Localization  timesformer1d  1.0000±0.0000  1.0000±0.0000\n",
       "19             Localization    transformer  0.9927±0.0022  0.9927±0.0022\n",
       "20             Localization            vit  0.9968±0.0019  0.9968±0.0019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\caption{Standard supervised evaluation on four core tasks. We report Accuracy and F1-score for each model.}\n",
      "\\label{tab:supervised-results}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{\n",
      "    >{\\centering\\arraybackslash}p{2.5cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}|\n",
      "    >{\\centering\\arraybackslash}p{1.8cm}\n",
      "}\n",
      "     \\toprule\n",
      "    Model & \\multicolumn{2}{c|}{\\textbf{Motion Source Recognition}} & \\multicolumn{2}{c|}{\\textbf{Fall Detection}} & \\multicolumn{2}{c|}{\\textbf{Breathing Detection}} & \\multicolumn{2}{c}{\\textbf{Localization}} \\\\\n",
      "    \\midrule\n",
      "\n",
      "MLP & 0.9886±0.0007 & 0.9886±0.0007 & 0.9216±0.0091 & 0.9217±0.0092 & -- & -- & 0.8714±0.0080 & 0.8690±0.0083 \\\\\n",
      "LSTM & 0.9842±0.0019 & 0.9842±0.0019 & 0.9493±0.0051 & 0.9492±0.0050 & -- & -- & 0.9912±0.0027 & 0.9912±0.0026 \\\\\n",
      "TRANSFORMER & 0.9861±0.0027 & 0.9861±0.0027 & 0.9428±0.0072 & 0.9426±0.0072 & -- & -- & 0.9927±0.0022 & 0.9927±0.0022 \\\\\n",
      "RESNET18 & 0.9956±0.0007 & 0.9956±0.0007 & 0.9488±0.0026 & 0.9489±0.0026 & -- & -- & 1.0000±0.0000 & 1.0000±0.0000 \\\\\n",
      "PATCHTST & 0.9886±0.0019 & 0.9886±0.0019 & 0.9403±0.0074 & 0.9403±0.0073 & -- & -- & 0.9991±0.0010 & 0.9991±0.0010 \\\\\n",
      "TIMESFORMER1D & 0.9838±0.0017 & 0.9839±0.0017 & 0.9386±0.0116 & 0.9387±0.0113 & -- & -- & 1.0000±0.0000 & 1.0000±0.0000 \\\\\n",
      "\\hline\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_list = [\"MotionSourceRecognition\", \"FallDetection\", \"BreathingDetection\", \"Localization\"]\n",
    "metric_columns = [\"test_accuracy\", \"test_f1_score\"]\n",
    "model_order=[\"mlp\", \"lstm\", \"transformer\", \"resnet18\", \"patchtst\", \"timesformer1d\"]\n",
    "\n",
    "summary_df, latex_code = generate_errorbar_summary_with_latex(df=results_df, \n",
    "                                                              task_list=task_list,\n",
    "                                                              metric_columns=metric_columns,\n",
    "                                                              model_order=model_order,\n",
    "                                                             precision=4)\n",
    "\n",
    "\n",
    "\n",
    "# 查看结果表格\n",
    "display(summary_df)\n",
    "\n",
    "# 打印 LaTeX 表格代码\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae23336c-b076-4aa3-8a3f-e4a1dd134707",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv('result_with_error_bar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f696d5e-37fc-447c-83ae-615c167edd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a04e7-aa39-42cf-a5f9-d2b1967af62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

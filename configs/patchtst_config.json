{
  "model": "patchtst",
  "emb_dim": 128,
  "depth": 4,
  "num_heads": 4,
  "patch_len": 16,
  "stride": 8,
  "dropout": 0.1,
  "head_dropout": 0.2,
  "batch_size": 32,
  "epochs": 30,
  "learning_rate": 0.0005,
  "weight_decay": 1e-5,
  "warmup_epochs": 5,
  "patience": 15
} 

